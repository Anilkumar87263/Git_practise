{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25881b0d-6def-4e1b-a53e-3f2279e0fdee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "spark.sql(\"USE globalretail_silver\")\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS silver_customers (\n",
    "    customer_id STRING,\n",
    "    name STRING,\n",
    "    email STRING,\n",
    "    country STRING,\n",
    "    customer_type STRING,\n",
    "    registration_date DATE,\n",
    "    age INT,\n",
    "    gender STRING,\n",
    "    total_purchases INT,\n",
    "    customer_segment STRING,\n",
    "    days_since_registration INT,\n",
    "    last_updated TIMESTAMP)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9f60586-3e93-40de-a2c6-3ea57c994800",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the last processed timestamp from silver layer\n",
    "last_processed_df = spark.sql(\"SELECT MAX(last_updated) as last_processed FROM silver_customers\")\n",
    "last_processed_timestamp = last_processed_df.collect()[0]['last_processed']\n",
    "\n",
    "if last_processed_timestamp is None:\n",
    "    last_processed_timestamp = \"1900-01-01T00:00:00.000+00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bc3c827-65be-48f2-a7a2-c08e740e505f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a temporary view of incremental bronze data\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW bronze_incremental AS\n",
    "SELECT *\n",
    "FROM globalretail_bronze.bronze_customer c where  c.ingestion_timestamp > '{last_processed_timestamp}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43c48d46-b747-4183-b07f-0061e9603b74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE globalretail_bronze.bronze_customer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33c2441a-815c-4273-823e-df3490e7bd48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"select * from globalretail_bronze.bronze_customer\")\n",
    "df = df.toDF(\"customer_id\", \"name\", \"email\", \"country\", \"customer_type\", \"registration_date\", \"age\", \"gender\", \"total_purchases\", \"customer_segment\")\n",
    "\n",
    "df.createOrReplaceTempView(\"bronze_incremental\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22ac890c-d7e0-4dd1-8876-ef80874e6286",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select * from bronze_incremental\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f8cc2e5-bab5-46cd-ba55-77b349a2abed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Validate email addresses (null or not null)\n",
    "#Valid age between 18 to 100\n",
    "#Create customer_segment as total_purchases > 10000 THEN 'High Value' if > 5000 THEN 'Medium Value'  ELSE 'Low Value'\n",
    "#days since user is registered in the system\n",
    "#Remove any junk records where total_purchase is negative number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8fa1ed6-fda9-4b81-bb75-c0a0d32c3ac2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW silver_incremental AS\n",
    "SELECT\n",
    "    customer_id,\n",
    "    name,\n",
    "    email,\n",
    "    country,\n",
    "    customer_type,\n",
    "    registration_date,\n",
    "    TRY_CAST(age AS INT) AS age,\n",
    "    gender,\n",
    "    total_purchases,\n",
    "    CASE\n",
    "        WHEN total_purchases > 10000 THEN 'High Value'\n",
    "        WHEN total_purchases > 5000 THEN 'Medium Value'\n",
    "        ELSE 'Low Value'\n",
    "    END AS customer_segment,\n",
    "    DATEDIFF(CURRENT_DATE(), registration_date) AS days_since_registration,\n",
    "    CURRENT_TIMESTAMP() AS last_updated\n",
    "FROM bronze_incremental\n",
    "WHERE \n",
    "    TRY_CAST(age AS INT) BETWEEN 18 AND 100\n",
    "    AND email IS NOT NULL\n",
    "    AND total_purchases >= 0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d151357a-085a-41bb-969a-0182e7039102",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DESCRIBE bronze_incremental\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c078f26-a7ce-442c-abd8-4c51ae75cab6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"select * from silver_incremental\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4910f3f1-55c4-48bb-b884-c03b7cae4585",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "MERGE INTO silver_customers target\n",
    "USING silver_incremental source\n",
    "ON target.customer_id = source.customer_id\n",
    "WHEN MATCHED THEN\n",
    "    UPDATE SET *\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT *\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ab92155-575d-4fe9-81ce-d3c9e0686dfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select count(*) from silver_customers\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silverlayer_customer_load_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
